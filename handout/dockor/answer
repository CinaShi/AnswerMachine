#!/usr/bin/python3 -W ignore::DeprecationWarning
# -*- coding:utf8 -*-
import sys
import spacy
import re
import codecs

from nltk.parse import CoreNLPParser
from nltk import sent_tokenize
from nltk.parse.corenlp import CoreNLPDependencyParser

dep_parser = CoreNLPDependencyParser(url='http://localhost:9000')
text = "jack is in the house"
question = "where is jack"


def resolve(corenlp_output):
    """ Transfer the word form of the antecedent to its associated pronominal anaphor(s) """
    for coref in corenlp_output['corefs']:
        mentions = corenlp_output['corefs'][coref]
        antecedent = mentions[0]  # the antecedent is the first mention in the coreference chain
        for j in range(1, len(mentions)):
            mention = mentions[j]
            if mention['type'] == 'PRONOMINAL':
                # get the attributes of the target mention in the corresponding sentence
                target_sentence = mention['sentNum']
                target_token = mention['startIndex'] - 1
                # transfer the antecedent's word form to the appropriate token in the sentence
                corenlp_output['sentences'][target_sentence - 1]['tokens'][target_token]['word'] = antecedent['text']


def print_resolved(corenlp_output):
    """ Print the "resolved" output """
    output = ""
    possessives = ['hers', 'his', 'their', 'theirs']
    for sentence in corenlp_output['sentences']:
        for token in sentence['tokens']:
            output_word = token['word']
            # check lemmas as well as tags for possessive pronouns in case of tagging errors
            if token['lemma'] in possessives or token['pos'] == 'PRP$':
                output_word += "'s"  # add the possessive morpheme
            output_word += token['after']
            # print(output_word, end='')
            # print("debug")
            output += output_word
    return output

def preprocessing(input_file):
	tagger = CoreNLPParser(url='http://localhost:9000')
	dep_parser = CoreNLPDependencyParser(url='http://localhost:9000')
	results = []
	with open(input_file, 'r') as f:
		i = 0
		for line in f:
			print("line " + str(i))
			print(len(line))
			if not line or line == "\n":
				continue
			tagger.parser_annotator='tokenize,ssplit,pos,lemma,ner,depparse,coref'
			output = tagger.api_call(line)
			resolve(output)
			output = print_resolved(output)
			tokens = sent_tokenize(output)
			for token in tokens:
				parses = dep_parser.parse(list(tokens))
				print(parses)
				results.append(parses)
			i += 1


#preprocessing("../data/set1/a1.txt")
tagger = CoreNLPParser(url='http://localhost:9000')
tagger.parser_annotator='tokenize,ssplit,pos,lemma,ner,depparse,coref'
output = tagger.api_call(text)
resolve(output)
new_text = print_resolved(output)

text_parses = dep_parser.parse(new_text.split())


ner_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='ner')


text_dep = []



for parse in text_parses:
	for governor, dep, dependent in parse.triples():
		text_dep.append((governor, dep, dependent))




def question_parser(question):
	question_dep = []
	wh_word = question.split()[0]

	question_parses = dep_parser.parse(question.split())

	for parse in question_parses:
		for governor, dep, dependent in parse.triples():
			question_dep.append((governor, dep, dependent))

	return question_dep, wh_word

def nsubj_answer(text_dep, key_word):
	answer = None
	for (governor, dep, dependent) in text_dep:
		gov_word, gov_tag = governor
		dep_word, dep_tag = dependent
		if gov_word == key_word and dep == 'nsubj':
			answer = dep_word
		elif dep_word == key_word and dep == 'nsubj':
			answer = gov_word

	return answer




def answer_from_dep_lists(text_dep, question_dep, wh_word):
	answer = None
	key_word = None

	is_doing = False
	is_where = False

	do_word_list = ["do","doing","did","done"]
	be_word_list = ["be","is","are","am","was","were"]

	for (governor, dep, dependent) in question_dep:
		gov_word, gov_tag = governor
		dep_word, dep_tag = dependent

		if gov_word == wh_word and dep == 'nsubj':
			key_word = dep_word
		elif dep_word == wh_word and dep == 'nsubj':
			key_word = gov_word

		### 1 solve "what-do"
		if (gov_word in do_word_list) and dep == 'dobj' and dep_word == "what": 
			is_doing = True
			do_word = gov_word

		### 2 solve "where"
		if dep == 'advmod' and dep_word == 'where' and (gov_word in be_word_list): 
			be_word = gov_word
			is_where = True

	answer = nsubj_answer(text_dep, key_word)

	### 1 solve "what-do"
	if answer == None and is_doing:
		for (governor, dep, dependent) in question_dep:
			gov_word, gov_tag = governor
			dep_word, dep_tag = dependent

			if gov_word == do_word and dep == 'nsubj':
				key_word = dep_word

	answer = nsubj_answer(text_dep, key_word)

	### 2 solve "where"
	if answer == None and is_where:
		for (governor, dep, dependent) in question_dep:
			gov_word, gov_tag = governor
			dep_word, dep_tag = dependent

			if gov_word == be_word and dep == 'nsubj':
				key_word = dep_word
	
	answer = nsubj_answer(text_dep, key_word)
	return answer

'''
question_dep, wh_word = question_parser(question)
answer = answer_from_dep_lists(text_dep, question_dep, wh_word)
print(answer)
print(text_dep)
print(question_dep)
'''


if __name__ == "__main__":
    input_file = sys.argv[1]
    question_file = sys.argv[2]


    with open(question_file, 'r')  as f:
        count = 0
        for line in f:
            count += 1
            print('A'+str(count))

